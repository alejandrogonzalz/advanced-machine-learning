{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuuvVBGWibnI"
   },
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "- Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
    "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:05.346453Z",
     "start_time": "2025-01-24T03:46:05.306484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#################################\n",
    "%matplotlib inline\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d48QB1yOibnS",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:06.679503Z",
     "start_time": "2025-01-24T03:46:05.350459Z"
    }
   },
   "source": [
    "DATA_PATH = './data/asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "olT4OWKHibnS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737577012183,
     "user_tz": 360,
     "elapsed": 5,
     "user": {
      "displayName": "ALEJANDRO González Almazán",
      "userId": "18200300479642110879"
     }
    },
    "outputId": "24f7b28e-2846-41cf-e9a2-2bde5eb0eefa",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:06.742644Z",
     "start_time": "2025-01-24T03:46:06.694750Z"
    }
   },
   "source": [
    "train_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5hcNzJUibnT"
   },
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5HN9JuusibnU",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:06.969517Z",
     "start_time": "2025-01-24T03:46:06.825580Z"
    }
   },
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "metadata": {
    "code_folding": [],
    "id": "ylUG3aq-ibnV",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:07.133103Z",
     "start_time": "2025-01-24T03:46:07.092148Z"
    }
   },
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    '''\n",
    "    Create a function that will allow you to split the previously loaded validation set\n",
    "    into valition and test.\n",
    "    '''\n",
    "    \"\"\"\n",
    "    Split the validation set into validation and test subsets.\n",
    "\n",
    "    Parameters:\n",
    "    x (array-like): Features of the dataset.\n",
    "    y (array-like): Labels corresponding to the features.\n",
    "    pct (float): Percentage of the data to allocate for the test set (default is 0.5).\n",
    "    shuffle (bool): Whether to shuffle the dataset before splitting (default is True).\n",
    "\n",
    "    Returns:\n",
    "    tuple: (x_val, y_val, x_test, y_test)\n",
    "        - x_val: Features for the validation subset.\n",
    "        - y_val: Labels for the validation subset.\n",
    "        - x_test: Features for the test subset.\n",
    "        - y_test: Labels for the test subset.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(x))\n",
    "        np.random.shuffle(indices)\n",
    "        x = np.array(x)[indices]\n",
    "        y = np.array(y)[indices]\n",
    "\n",
    "    split_idx = int(len(x) * (1 - pct))\n",
    "\n",
    "    x_val, x_test = x[:split_idx], x[split_idx:]\n",
    "    y_val, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    return x_val, y_val, x_test, y_test"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g5ZrjKNiibnW",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:07.211286Z",
     "start_time": "2025-01-24T03:46:07.137109Z"
    }
   },
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ],
   "outputs": [],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9BfVB--IibnX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737589849951,
     "user_tz": 360,
     "elapsed": 132,
     "user": {
      "displayName": "ALEJANDRO González Almazán",
      "userId": "18200300479642110879"
     }
    },
    "outputId": "75d8a34c-9b76-4ad9-88a0-18b0a1556427",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:07.858541Z",
     "start_time": "2025-01-24T03:46:07.821999Z"
    }
   },
   "source": [
    "### The following\n",
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY5j2FVxibnY"
   },
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std\n",
    "\n",
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ],
   "metadata": {
    "id": "ceqFb1dmba_C",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.255118Z",
     "start_time": "2025-01-24T03:46:08.112827Z"
    }
   },
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCvAxuRfibnY"
   },
   "source": [
    "### Graficar muestras"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_image(data, labels, index):\n",
    "    '''\n",
    "    Plots a single 28x28 grayscale image with the title that indicates the letter it represents.\n",
    "    Parameters:\n",
    "    - data: Dataset containing the image data (e.g., x_train, x_val)\n",
    "    - labels: Dataset containing the corresponding labels (e.g., y_train, y_val)\n",
    "    - index: Index of the image in the dataset\n",
    "    '''\n",
    "    # Reshape the image data back into 28x28 format for visualization\n",
    "    image = data[index].reshape(28, 28)\n",
    "\n",
    "    # Convert the label to ASCII (A-I: 65-73, K-Y: 75-89 in ASCII)\n",
    "    label = labels[index]\n",
    "    if label >= 9:  # Adjust labels for J (label 9 and above)\n",
    "        ascii_letter = chr(label + 66)  # Skip J (add 1 to adjust for the missing J)\n",
    "    else:\n",
    "        ascii_letter = chr(label + 65)  # Labels A-I remain unchanged\n",
    "\n",
    "    # Plot the image with the corresponding label as title\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"This is the letter: {ascii_letter}\")\n",
    "    plt.axis('off')  # Hide axes for cleaner visualization\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "SZou5CZub7aF",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.309798Z",
     "start_time": "2025-01-24T03:46:08.274029Z"
    }
   },
   "outputs": [],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9_NJGNyibnZ"
   },
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6-wDlQ2ibnZ"
   },
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjgF_kPQibna"
   },
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_sUIyGvLibna",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.367195Z",
     "start_time": "2025-01-24T03:46:08.327133Z"
    }
   },
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": [
    "for i in range(0,3):\n",
    "    plot_image(x_train, y_train, i)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q_4eULOtcPbF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737590125250,
     "user_tz": 360,
     "elapsed": 517,
     "user": {
      "displayName": "ALEJANDRO González Almazán",
      "userId": "18200300479642110879"
     }
    },
    "outputId": "04da1ff5-0b20-4ed3-c45b-840fcc86c341",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.537903Z",
     "start_time": "2025-01-24T03:46:08.386497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95syEfngibna"
   },
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class np_tensor(np.ndarray): pass"
   ],
   "metadata": {
    "id": "gzmhYVZIcajo",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.592747Z",
     "start_time": "2025-01-24T03:46:08.558575Z"
    }
   },
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pxqZx-kibna"
   },
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Linear():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        '''\n",
    "        Init parameters utilizando Kaiming He\n",
    "        '''\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    def __call__(self, X): # esta el foward de la clase lineal\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)\n"
   ],
   "metadata": {
    "id": "fZQnLK91cb8p",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.645415Z",
     "start_time": "2025-01-24T03:46:08.609143Z"
    }
   },
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTfoXcGdibnb"
   },
   "source": [
    "### Clase ReLU"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class ReLU():\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ],
   "metadata": {
    "id": "Ho9zfUgscdZr",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.699563Z",
     "start_time": "2025-01-24T03:46:08.663446Z"
    }
   },
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9UXrs7nibnb"
   },
   "source": [
    "### Clase Sequential"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Sequential_layers():\n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        layers - lista que contiene objetos de tipo Linear, ReLU\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    def __call__(self, X):\n",
    "        self.x = X\n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))"
   ],
   "metadata": {
    "id": "-f4B8TcXcfEC",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.755189Z",
     "start_time": "2025-01-24T03:46:08.717972Z"
    }
   },
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xrIKoBxibnb"
   },
   "source": [
    "### Cost Function"
   ]
  },
  {
   "metadata": {
    "id": "Yj911HtJcjdM",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.809798Z",
     "start_time": "2025-01-24T03:46:08.772946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "    probs = exp_scores / exp_scores.sum(axis = 0)\n",
    "    preds = probs.copy()\n",
    "    # Costo\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "    # Calcular gradientes\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1 #dl/dx\n",
    "    x.grad = probs.copy()\n",
    "\n",
    "    return preds, cost"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "id": "usUs79fcibnb"
   },
   "cell_type": "markdown",
   "source": "### Loop de entrenamiento"
  },
  {
   "metadata": {
    "id": "0kBAYywXchL4",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:48:08.750260Z",
     "start_time": "2025-01-24T03:48:08.712793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate = 1e-3):\n",
    "    for epoch in range(epochs):\n",
    "        for i, (x, y) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "            scores = model(x.T.view(np_tensor))\n",
    "            _, cost = softmaxXEntropy(scores, y)\n",
    "            model.backward()\n",
    "            model.update(learning_rate)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, cost: {cost}, accuracy: {accuracy(x_val, y_val, model, mb_size)}')\n",
    "\n",
    "    final_accuracy = accuracy(x_val, y_val, model, mb_size)\n",
    "    return final_accuracy"
   ],
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "id": "CjBXlOj6ibnb"
   },
   "cell_type": "markdown",
   "source": "### Create your model and train it"
  },
  {
   "metadata": {
    "id": "xOxoo6NSibnc",
    "ExecuteTime": {
     "end_time": "2025-01-24T03:46:08.915073Z",
     "start_time": "2025-01-24T03:46:08.879137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(x, y, model, mb_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (x, y) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "        pred = model(x.T.view(np_tensor))\n",
    "        correct += np.sum(np.argmax(pred, axis=0) == y.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    return correct/total"
   ],
   "outputs": [],
   "execution_count": 110
  },
  {
   "metadata": {
    "id": "99e9TmQ1ibnc"
   },
   "cell_type": "markdown",
   "source": "### Test your model on Random data from your test set"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T03:48:11.603439Z",
     "start_time": "2025-01-24T03:48:11.564031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "def grid_search_train(train, nodes, epochs, mb_size, learning_rate):\n",
    "    param_grid = list(itertools.product(nodes, epochs, mb_size, learning_rate))\n",
    "\n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_params = None\n",
    "\n",
    "    for (nodes ,epochs, mb_size, learning_rate) in param_grid:\n",
    "        print(f\"Training with params:nodes={nodes}, epochs={epochs}, mb_size={mb_size}, learning_rate={learning_rate}\")\n",
    "        model=Sequential_layers([Linear(784, nodes), ReLU(), Linear(nodes, 24)])\n",
    "        accuracy = train(model, epochs, mb_size, learning_rate)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_params = (nodes, epochs, mb_size, learning_rate)\n",
    "            best_model = model\n",
    "\n",
    "        print(f\"Accuracy: {accuracy}, Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "    print(f\"Best parameters:nodes={best_params[0]}, epochs={best_params[1]}, mb_size={best_params[2]}, learning_rate={best_params[3]}\")\n",
    "    return best_model, best_params, best_accuracy"
   ],
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-24T04:12:51.255134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nodes = [64, 128, 256, 512]\n",
    "epochs = [10, 20, 30]\n",
    "mb_size = [16, 32, 64, 128]\n",
    "learning_rate = [0.001, 0.002, 0.005, 0.007, 0.01]\n",
    "\n",
    "best_model, best_params, best_accuracy = grid_search_train(train, nodes, epochs, mb_size,learning_rate)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:nodes=64, epochs=10, mb_size=16, learning_rate=0.001\n",
      "Epoch 1/10, cost: 0.13793085500573712, accuracy: 0.7571109871723368\n",
      "Epoch 2/10, cost: 0.1258491071842858, accuracy: 0.762409369771333\n",
      "Epoch 3/10, cost: 0.030289909707473375, accuracy: 0.7674288901282766\n",
      "Epoch 4/10, cost: 0.018566759469110183, accuracy: 0.77356385945343\n",
      "Epoch 5/10, cost: 0.024064964260362774, accuracy: 0.7730061349693251\n",
      "Epoch 6/10, cost: 0.006257803504498663, accuracy: 0.7691020635805912\n",
      "Epoch 7/10, cost: 0.019113735406254436, accuracy: 0.7718906860011154\n",
      "Epoch 8/10, cost: 0.010345420214776848, accuracy: 0.7702175125488009\n",
      "Epoch 9/10, cost: 0.004712342275196931, accuracy: 0.7749581706636921\n",
      "Epoch 10/10, cost: 0.003901348712303711, accuracy: 0.7738427216954824\n",
      "Accuracy: 0.7738427216954824, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=16, learning_rate=0.002\n",
      "Epoch 1/10, cost: 0.14418447652009697, accuracy: 0.7200223089793641\n",
      "Epoch 2/10, cost: 0.02643874350846908, accuracy: 0.7445621862799777\n",
      "Epoch 3/10, cost: 0.009003563847251548, accuracy: 0.7484662576687117\n",
      "Epoch 4/10, cost: 0.009631320727120132, accuracy: 0.7557166759620747\n",
      "Epoch 5/10, cost: 0.003614192616675388, accuracy: 0.7596207473508088\n",
      "Epoch 6/10, cost: 0.0026166405958939916, accuracy: 0.758505298382599\n",
      "Epoch 7/10, cost: 0.0029516254104700094, accuracy: 0.7551589514779699\n",
      "Epoch 8/10, cost: 0.002791308891074648, accuracy: 0.7576687116564417\n",
      "Epoch 9/10, cost: 0.0020802390691329925, accuracy: 0.7601784718349136\n",
      "Epoch 10/10, cost: 0.0022990032869342697, accuracy: 0.7568321249302844\n",
      "Accuracy: 0.7568321249302844, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=16, learning_rate=0.005\n",
      "Epoch 1/10, cost: 0.00880547251490852, accuracy: 0.7540435025097602\n",
      "Epoch 2/10, cost: 0.004562530145278265, accuracy: 0.7618516452872282\n",
      "Epoch 3/10, cost: 0.0017891805099551554, accuracy: 0.760457334076966\n",
      "Epoch 4/10, cost: 0.0012923260342061508, accuracy: 0.7746793084216397\n",
      "Epoch 5/10, cost: 0.0013472023850109624, accuracy: 0.7674288901282766\n",
      "Epoch 6/10, cost: 0.0010458667699187153, accuracy: 0.7707752370329057\n",
      "Epoch 7/10, cost: 0.0007693429880256936, accuracy: 0.7724484104852203\n",
      "Epoch 8/10, cost: 0.002417375993349122, accuracy: 0.7702175125488009\n",
      "Epoch 9/10, cost: 0.0016563466767667507, accuracy: 0.769659788064696\n",
      "Epoch 10/10, cost: 0.0007470850183861407, accuracy: 0.769659788064696\n",
      "Accuracy: 0.769659788064696, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=16, learning_rate=0.007\n",
      "Epoch 1/10, cost: 0.00537379030994242, accuracy: 0.7660345789180145\n",
      "Epoch 2/10, cost: 0.005579130689613318, accuracy: 0.769659788064696\n",
      "Epoch 3/10, cost: 0.001031796763974225, accuracy: 0.7688232013385388\n",
      "Epoch 4/10, cost: 0.0003327899531392975, accuracy: 0.7663134411600669\n",
      "Epoch 5/10, cost: 0.000524441386399983, accuracy: 0.7693809258226436\n",
      "Epoch 6/10, cost: 0.0010025450474664928, accuracy: 0.7671500278862242\n",
      "Epoch 7/10, cost: 0.0017303210154290078, accuracy: 0.7688232013385388\n",
      "Epoch 8/10, cost: 0.0007416314818480148, accuracy: 0.7660345789180145\n",
      "Epoch 9/10, cost: 0.0006631629476644724, accuracy: 0.7660345789180145\n",
      "Epoch 10/10, cost: 0.00024289373466852807, accuracy: 0.7674288901282766\n",
      "Accuracy: 0.7674288901282766, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=16, learning_rate=0.01\n",
      "Epoch 1/10, cost: 0.021420220890059107, accuracy: 0.694366982710541\n",
      "Epoch 2/10, cost: 0.0001285765240672043, accuracy: 0.7339654210819855\n",
      "Epoch 3/10, cost: 0.0002175775449673018, accuracy: 0.760457334076966\n",
      "Epoch 4/10, cost: 6.883196003132998e-06, accuracy: 0.7615727830451757\n",
      "Epoch 5/10, cost: 0.0005397424375264599, accuracy: 0.7640825432236475\n",
      "Epoch 6/10, cost: 4.259872448855352e-05, accuracy: 0.7643614054657\n",
      "Epoch 7/10, cost: 6.486498707509312e-05, accuracy: 0.7643614054657\n",
      "Epoch 8/10, cost: 4.3712343415494945e-05, accuracy: 0.7657557166759621\n",
      "Epoch 9/10, cost: 7.208216732836018e-05, accuracy: 0.7674288901282766\n",
      "Epoch 10/10, cost: 6.645370786040944e-07, accuracy: 0.7671500278862242\n",
      "Accuracy: 0.7671500278862242, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=32, learning_rate=0.001\n",
      "Epoch 1/10, cost: 0.14416174046095895, accuracy: 0.72643614054657\n",
      "Epoch 2/10, cost: 0.07773798190572498, accuracy: 0.7373117679866146\n",
      "Epoch 3/10, cost: 0.03491540583707669, accuracy: 0.7484662576687117\n",
      "Epoch 4/10, cost: 0.023807960997852696, accuracy: 0.7532069157836029\n",
      "Epoch 5/10, cost: 0.017357695670274453, accuracy: 0.7537646402677077\n",
      "Epoch 6/10, cost: 0.016884359880993068, accuracy: 0.7590630228667038\n",
      "Epoch 7/10, cost: 0.008069679114464937, accuracy: 0.756553262688232\n",
      "Epoch 8/10, cost: 0.009088043687689885, accuracy: 0.7551589514779699\n",
      "Epoch 9/10, cost: 0.008089589166910756, accuracy: 0.7571109871723368\n",
      "Epoch 10/10, cost: 0.003383978701591969, accuracy: 0.7571109871723368\n",
      "Accuracy: 0.7571109871723368, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=32, learning_rate=0.002\n",
      "Epoch 1/10, cost: 0.04355450461565332, accuracy: 0.7532069157836029\n",
      "Epoch 2/10, cost: 0.025238759390496083, accuracy: 0.7579475738984941\n",
      "Epoch 3/10, cost: 0.015646001210916236, accuracy: 0.756553262688232\n",
      "Epoch 4/10, cost: 0.009758194381455627, accuracy: 0.7548800892359174\n",
      "Epoch 5/10, cost: 0.007653955131857981, accuracy: 0.7640825432236475\n",
      "Epoch 6/10, cost: 0.0034335930107233193, accuracy: 0.754601226993865\n",
      "Epoch 7/10, cost: 0.005282861795647007, accuracy: 0.7520914668153932\n",
      "Epoch 8/10, cost: 0.006655253868772397, accuracy: 0.7554378137200223\n",
      "Epoch 9/10, cost: 0.0025359508804441372, accuracy: 0.7559955382041271\n",
      "Epoch 10/10, cost: 0.0021568825720173564, accuracy: 0.7562744004461796\n",
      "Accuracy: 0.7562744004461796, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=32, learning_rate=0.005\n",
      "Epoch 1/10, cost: 0.012664506037809135, accuracy: 0.7646402677077524\n",
      "Epoch 2/10, cost: 0.006701596899246172, accuracy: 0.7691020635805912\n",
      "Epoch 3/10, cost: 0.003989539710107665, accuracy: 0.7621305075292806\n",
      "Epoch 4/10, cost: 0.0012346143140145496, accuracy: 0.7674288901282766\n",
      "Epoch 5/10, cost: 0.0012214831653271684, accuracy: 0.7668711656441718\n",
      "Epoch 6/10, cost: 0.0007488037791595308, accuracy: 0.7671500278862242\n",
      "Epoch 7/10, cost: 0.0008197175265119218, accuracy: 0.7671500278862242\n",
      "Epoch 8/10, cost: 0.001178844082016071, accuracy: 0.7682654768544339\n",
      "Epoch 9/10, cost: 0.0007276875470644178, accuracy: 0.7691020635805912\n",
      "Epoch 10/10, cost: 0.0008735701657726897, accuracy: 0.769659788064696\n",
      "Accuracy: 0.769659788064696, Best Accuracy: 0.7738427216954824\n",
      "Training with params:nodes=64, epochs=10, mb_size=32, learning_rate=0.007\n",
      "Epoch 1/10, cost: 0.012278512729954989, accuracy: 0.7780256553262688\n",
      "Epoch 2/10, cost: 0.002396028032304264, accuracy: 0.7830451756832125\n",
      "Epoch 3/10, cost: 0.0010706795578574527, accuracy: 0.7838817624093698\n",
      "Epoch 4/10, cost: 0.001167437460552388, accuracy: 0.7863915225878416\n",
      "Epoch 5/10, cost: 0.0017381178947795952, accuracy: 0.7819297267150028\n",
      "Epoch 6/10, cost: 0.0006515342844601016, accuracy: 0.7816508644729504\n",
      "Epoch 7/10, cost: 0.0007374544686239046, accuracy: 0.779419966536531\n",
      "Epoch 8/10, cost: 0.0007975757006042803, accuracy: 0.7830451756832125\n",
      "Epoch 9/10, cost: 0.00040365555890093985, accuracy: 0.7844394868934746\n",
      "Epoch 10/10, cost: 0.00026780077650326095, accuracy: 0.7824874511991077\n",
      "Accuracy: 0.7824874511991077, Best Accuracy: 0.7824874511991077\n",
      "Training with params:nodes=64, epochs=10, mb_size=32, learning_rate=0.01\n",
      "Epoch 1/10, cost: 0.18896659802934235, accuracy: 0.7189068600111544\n",
      "Epoch 2/10, cost: 0.00843914101916968, accuracy: 0.7495817066369214\n",
      "Epoch 3/10, cost: 0.18878810175736532, accuracy: 0.7002230897936419\n",
      "Epoch 4/10, cost: 0.0344491628689748, accuracy: 0.7334076965978806\n",
      "Epoch 5/10, cost: 0.003502481154241929, accuracy: 0.7233686558839934\n",
      "Epoch 6/10, cost: 1.4530195902258578, accuracy: 0.7027328499721138\n",
      "Epoch 7/10, cost: 0.00034008765111692046, accuracy: 0.7236475181260458\n",
      "Epoch 8/10, cost: 2.6808062502556016e-05, accuracy: 0.730340211935304\n",
      "Epoch 9/10, cost: 7.006350872714636e-07, accuracy: 0.7381483547127718\n",
      "Epoch 10/10, cost: 1.6506434992407197e-05, accuracy: 0.7417735638594535\n",
      "Accuracy: 0.7417735638594535, Best Accuracy: 0.7824874511991077\n",
      "Training with params:nodes=64, epochs=10, mb_size=64, learning_rate=0.001\n",
      "Epoch 1/10, cost: 0.17440910763633538, accuracy: 0.7295036252091467\n",
      "Epoch 2/10, cost: 0.06949358680054987, accuracy: 0.7554378137200223\n",
      "Epoch 3/10, cost: 0.024786580257223384, accuracy: 0.7671500278862242\n",
      "Epoch 4/10, cost: 0.01882947918397927, accuracy: 0.7668711656441718\n",
      "Epoch 5/10, cost: 0.012255885330270375, accuracy: 0.7668711656441718\n",
      "Epoch 6/10, cost: 0.009620225404500886, accuracy: 0.7688232013385388\n",
      "Epoch 7/10, cost: 0.010997702246245977, accuracy: 0.7718906860011154\n",
      "Epoch 8/10, cost: 0.007161227634136599, accuracy: 0.7668711656441718\n",
      "Epoch 9/10, cost: 0.006678932643239223, accuracy: 0.7665923034021194\n",
      "Epoch 10/10, cost: 0.0064531341089730755, accuracy: 0.7663134411600669\n",
      "Accuracy: 0.7663134411600669, Best Accuracy: 0.7824874511991077\n",
      "Training with params:nodes=64, epochs=10, mb_size=64, learning_rate=0.002\n",
      "Epoch 1/10, cost: 0.08092022747516123, accuracy: 0.7504182933630786\n",
      "Epoch 2/10, cost: 0.0176999532190283, accuracy: 0.7721695482431679\n",
      "Epoch 3/10, cost: 0.015925426775397888, accuracy: 0.7732849972113776\n",
      "Epoch 4/10, cost: 0.006113471300138587, accuracy: 0.7774679308421639\n",
      "Epoch 5/10, cost: 0.007098790697651437, accuracy: 0.77356385945343\n",
      "Epoch 6/10, cost: 0.006474530328346755, accuracy: 0.7677077523703291\n",
      "Epoch 7/10, cost: 0.005263443330599578, accuracy: 0.7688232013385388\n",
      "Epoch 8/10, cost: 0.0027702848782751206, accuracy: 0.7685443390964863\n",
      "Epoch 9/10, cost: 0.0018241950185826925, accuracy: 0.7688232013385388\n",
      "Epoch 10/10, cost: 0.0030971441979301163, accuracy: 0.7679866146123815\n",
      "Accuracy: 0.7679866146123815, Best Accuracy: 0.7824874511991077\n",
      "Training with params:nodes=64, epochs=10, mb_size=64, learning_rate=0.005\n",
      "Epoch 1/10, cost: 0.029833720701042482, accuracy: 0.7691020635805912\n",
      "Epoch 2/10, cost: 0.005635417197929274, accuracy: 0.7777467930842163\n",
      "Epoch 3/10, cost: 0.0032825309180694187, accuracy: 0.7771890686001115\n",
      "Epoch 4/10, cost: 0.0026437334939641613, accuracy: 0.7777467930842163\n",
      "Epoch 5/10, cost: 0.0024691340636390354, accuracy: 0.783324037925265\n",
      "Epoch 6/10, cost: 0.002319251339618298, accuracy: 0.7877858337981037\n",
      "Epoch 7/10, cost: 0.0010923180473865705, accuracy: 0.7891801450083659\n",
      "Epoch 8/10, cost: 0.0009848430436848424, accuracy: 0.783324037925265\n",
      "Epoch 9/10, cost: 0.0007133400212865652, accuracy: 0.7861126603457892\n",
      "Epoch 10/10, cost: 0.0010293923087515194, accuracy: 0.7875069715560513\n",
      "Accuracy: 0.7875069715560513, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=64, learning_rate=0.007\n",
      "Epoch 1/10, cost: 0.0179319812997701, accuracy: 0.756553262688232\n",
      "Epoch 2/10, cost: 0.001726088702985229, accuracy: 0.7660345789180145\n",
      "Epoch 3/10, cost: 0.0014413355083606634, accuracy: 0.7679866146123815\n",
      "Epoch 4/10, cost: 0.001090474080927057, accuracy: 0.7674288901282766\n",
      "Epoch 5/10, cost: 0.0009428052649858069, accuracy: 0.7693809258226436\n",
      "Epoch 6/10, cost: 0.000767842929316318, accuracy: 0.7699386503067485\n",
      "Epoch 7/10, cost: 0.0006343040339284871, accuracy: 0.7732849972113776\n",
      "Epoch 8/10, cost: 0.0005377481225586621, accuracy: 0.7763524818739542\n",
      "Epoch 9/10, cost: 0.00041802702145519685, accuracy: 0.7777467930842163\n",
      "Epoch 10/10, cost: 0.0002632010110234132, accuracy: 0.7766313441160066\n",
      "Accuracy: 0.7766313441160066, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=64, learning_rate=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_1360\\1990919710.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = np.sum(-np.log(y_hat)) / batch_size\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_1360\\1990919710.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  exp_scores = np.exp(x)\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_1360\\1990919710.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = exp_scores / exp_scores.sum(axis = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 2/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 3/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 4/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 5/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 6/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 7/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 8/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 9/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 10/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Accuracy: 0.04656999442275516, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=128, learning_rate=0.001\n",
      "Epoch 1/10, cost: 0.17462055294150153, accuracy: 0.7105409927495817\n",
      "Epoch 2/10, cost: 0.04269725089865439, accuracy: 0.7401003904071388\n",
      "Epoch 3/10, cost: 0.02860915381833175, accuracy: 0.745398773006135\n",
      "Epoch 4/10, cost: 0.020251406544298082, accuracy: 0.7448410485220301\n",
      "Epoch 5/10, cost: 0.012470032730857632, accuracy: 0.7445621862799777\n",
      "Epoch 6/10, cost: 0.012351010414962811, accuracy: 0.7448410485220301\n",
      "Epoch 7/10, cost: 0.010367665776320126, accuracy: 0.7479085331846068\n",
      "Epoch 8/10, cost: 0.010087903828961554, accuracy: 0.7467930842163971\n",
      "Epoch 9/10, cost: 0.007321330653017311, accuracy: 0.7462353597322923\n",
      "Epoch 10/10, cost: 0.005352295577722697, accuracy: 0.7462353597322923\n",
      "Accuracy: 0.7462353597322923, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=128, learning_rate=0.002\n",
      "Epoch 1/10, cost: 0.08492368962705588, accuracy: 0.7593418851087562\n",
      "Epoch 2/10, cost: 0.020939813413600926, accuracy: 0.7629670942554378\n",
      "Epoch 3/10, cost: 0.011490799802069268, accuracy: 0.7593418851087562\n",
      "Epoch 4/10, cost: 0.007675848452582846, accuracy: 0.7629670942554378\n",
      "Epoch 5/10, cost: 0.006480184369232164, accuracy: 0.7632459564974903\n",
      "Epoch 6/10, cost: 0.003444388001828147, accuracy: 0.7638036809815951\n",
      "Epoch 7/10, cost: 0.003990339430274486, accuracy: 0.7610150585610709\n",
      "Epoch 8/10, cost: 0.0034102079580616332, accuracy: 0.7654768544339097\n",
      "Epoch 9/10, cost: 0.004528505414863717, accuracy: 0.7663134411600669\n",
      "Epoch 10/10, cost: 0.001958125552944576, accuracy: 0.7663134411600669\n",
      "Accuracy: 0.7663134411600669, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=128, learning_rate=0.005\n",
      "Epoch 1/10, cost: 0.5635987821458963, accuracy: 0.67930842163971\n",
      "Epoch 2/10, cost: 0.015916793131429508, accuracy: 0.7384272169548243\n",
      "Epoch 3/10, cost: 0.00512414622651766, accuracy: 0.7389849414389291\n",
      "Epoch 4/10, cost: 0.0032817121253935254, accuracy: 0.7403792526491912\n",
      "Epoch 5/10, cost: 0.0013789384754465599, accuracy: 0.7440044617958729\n",
      "Epoch 6/10, cost: 0.001879736692606276, accuracy: 0.7420524261015059\n",
      "Epoch 7/10, cost: 0.0013790475668154908, accuracy: 0.7417735638594535\n",
      "Epoch 8/10, cost: 0.0013648500885507495, accuracy: 0.7467930842163971\n",
      "Epoch 9/10, cost: 0.001040015324012459, accuracy: 0.7456776352481874\n",
      "Epoch 10/10, cost: 0.0005987615550039364, accuracy: 0.7467930842163971\n",
      "Accuracy: 0.7467930842163971, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=128, learning_rate=0.007\n",
      "Epoch 1/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 2/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 3/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 4/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 5/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 6/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 7/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 8/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 9/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 10/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Accuracy: 0.04656999442275516, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=10, mb_size=128, learning_rate=0.01\n",
      "Epoch 1/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 2/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 3/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 4/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 5/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 6/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 7/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 8/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 9/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Epoch 10/10, cost: nan, accuracy: 0.04656999442275516\n",
      "Accuracy: 0.04656999442275516, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=16, learning_rate=0.001\n",
      "Epoch 1/20, cost: 0.1868236812589145, accuracy: 0.6982710540992749\n",
      "Epoch 2/20, cost: 0.019499873528428333, accuracy: 0.7320133853876185\n",
      "Epoch 3/20, cost: 0.03667297044508551, accuracy: 0.7384272169548243\n",
      "Epoch 4/20, cost: 0.03173489146023358, accuracy: 0.741494701617401\n",
      "Epoch 5/20, cost: 0.013154445930392729, accuracy: 0.7392638036809815\n",
      "Epoch 6/20, cost: 0.005660594718620255, accuracy: 0.7398215281650864\n",
      "Epoch 7/20, cost: 0.011428037475713193, accuracy: 0.7451199107640826\n",
      "Epoch 8/20, cost: 0.007590610444763205, accuracy: 0.7403792526491912\n",
      "Epoch 9/20, cost: 0.010620958540638119, accuracy: 0.7426101505856108\n",
      "Epoch 10/20, cost: 0.015557619032039722, accuracy: 0.7420524261015059\n",
      "Epoch 11/20, cost: 0.006560469622030764, accuracy: 0.7451199107640826\n",
      "Epoch 12/20, cost: 0.004795965931237465, accuracy: 0.7476296709425544\n",
      "Epoch 13/20, cost: 0.004221859588012423, accuracy: 0.7445621862799777\n",
      "Epoch 14/20, cost: 0.002647536857540259, accuracy: 0.7467930842163971\n",
      "Epoch 15/20, cost: 0.0037252826808979104, accuracy: 0.7487451199107641\n",
      "Epoch 16/20, cost: 0.005679830047416031, accuracy: 0.747350808700502\n",
      "Epoch 17/20, cost: 0.001740534052171261, accuracy: 0.7459564974902398\n",
      "Epoch 18/20, cost: 0.010913778480635215, accuracy: 0.747350808700502\n",
      "Epoch 19/20, cost: 0.007710776119143768, accuracy: 0.7476296709425544\n",
      "Epoch 20/20, cost: 0.0030145923956796244, accuracy: 0.7481873954266592\n",
      "Accuracy: 0.7481873954266592, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=16, learning_rate=0.002\n",
      "Epoch 1/20, cost: 0.05274221143863185, accuracy: 0.7593418851087562\n",
      "Epoch 2/20, cost: 0.014772752932568722, accuracy: 0.7534857780256553\n",
      "Epoch 3/20, cost: 0.007375266937941977, accuracy: 0.7576687116564417\n",
      "Epoch 4/20, cost: 0.003585126434354081, accuracy: 0.7543223647518126\n",
      "Epoch 5/20, cost: 0.003854523440438265, accuracy: 0.754601226993865\n",
      "Epoch 6/20, cost: 0.005960855743923573, accuracy: 0.7562744004461796\n",
      "Epoch 7/20, cost: 0.0031743307550240597, accuracy: 0.7582264361405465\n",
      "Epoch 8/20, cost: 0.00426486252226941, accuracy: 0.7571109871723368\n",
      "Epoch 9/20, cost: 0.004401200347491408, accuracy: 0.7562744004461796\n",
      "Epoch 10/20, cost: 0.0032822480676757775, accuracy: 0.7548800892359174\n",
      "Epoch 11/20, cost: 0.0031407662804451477, accuracy: 0.7543223647518126\n",
      "Epoch 12/20, cost: 0.0013270176634229962, accuracy: 0.7504182933630786\n",
      "Epoch 13/20, cost: 0.001292033746187484, accuracy: 0.7529280535415505\n",
      "Epoch 14/20, cost: 0.0013103189906708002, accuracy: 0.7515337423312883\n",
      "Epoch 15/20, cost: 0.0030763967966595906, accuracy: 0.7532069157836029\n",
      "Epoch 16/20, cost: 0.0018406868267442482, accuracy: 0.7498605688789738\n",
      "Epoch 17/20, cost: 0.002192244226584926, accuracy: 0.7498605688789738\n",
      "Epoch 18/20, cost: 0.0007769347585894048, accuracy: 0.7481873954266592\n",
      "Epoch 19/20, cost: 0.0025005104303665203, accuracy: 0.7493028443948689\n",
      "Epoch 20/20, cost: 0.0007974027965655984, accuracy: 0.7495817066369214\n",
      "Accuracy: 0.7495817066369214, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=16, learning_rate=0.005\n",
      "Epoch 1/20, cost: 0.009381019462676995, accuracy: 0.7671500278862242\n",
      "Epoch 2/20, cost: 0.006298970692163754, accuracy: 0.7721695482431679\n",
      "Epoch 3/20, cost: 0.006430060678250401, accuracy: 0.7760736196319018\n",
      "Epoch 4/20, cost: 0.0021431072929752634, accuracy: 0.7780256553262688\n",
      "Epoch 5/20, cost: 0.003577690605170812, accuracy: 0.7777467930842163\n",
      "Epoch 6/20, cost: 0.0005724682895562426, accuracy: 0.7752370329057445\n",
      "Epoch 7/20, cost: 0.001154212609149502, accuracy: 0.7760736196319018\n",
      "Epoch 8/20, cost: 0.0007533540912063211, accuracy: 0.7732849972113776\n",
      "Epoch 9/20, cost: 0.0012271397736321442, accuracy: 0.7749581706636921\n",
      "Epoch 10/20, cost: 0.0007775338877926831, accuracy: 0.7746793084216397\n",
      "Epoch 11/20, cost: 0.0008408050048603316, accuracy: 0.7746793084216397\n",
      "Epoch 12/20, cost: 0.0008089781164658825, accuracy: 0.775515895147797\n",
      "Epoch 13/20, cost: 0.00044721037368063957, accuracy: 0.775515895147797\n",
      "Epoch 14/20, cost: 0.00041971245709477315, accuracy: 0.7752370329057445\n",
      "Epoch 15/20, cost: 0.0006536005573332745, accuracy: 0.7744004461795873\n",
      "Epoch 16/20, cost: 0.0010626090901254396, accuracy: 0.7732849972113776\n",
      "Epoch 17/20, cost: 0.0003964879889328409, accuracy: 0.7744004461795873\n",
      "Epoch 18/20, cost: 8.20410828110241e-05, accuracy: 0.7746793084216397\n",
      "Epoch 19/20, cost: 0.0003291480944440477, accuracy: 0.77356385945343\n",
      "Epoch 20/20, cost: 0.0005843927748927098, accuracy: 0.7746793084216397\n",
      "Accuracy: 0.7746793084216397, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=16, learning_rate=0.007\n",
      "Epoch 1/20, cost: 0.0038328633293667133, accuracy: 0.760457334076966\n",
      "Epoch 2/20, cost: 0.00294824487496203, accuracy: 0.7682654768544339\n",
      "Epoch 3/20, cost: 0.0019869571237602205, accuracy: 0.7730061349693251\n",
      "Epoch 4/20, cost: 0.0005819422440796057, accuracy: 0.7727272727272727\n",
      "Epoch 5/20, cost: 0.000677958926185721, accuracy: 0.7665923034021194\n",
      "Epoch 6/20, cost: 0.0009670445025724208, accuracy: 0.7713329615170106\n",
      "Epoch 7/20, cost: 0.0005724506196441449, accuracy: 0.7688232013385388\n",
      "Epoch 8/20, cost: 0.0004577740027558238, accuracy: 0.7704963747908533\n",
      "Epoch 9/20, cost: 0.00033262942315093804, accuracy: 0.7738427216954824\n",
      "Epoch 10/20, cost: 0.001334208545187808, accuracy: 0.7671500278862242\n",
      "Epoch 11/20, cost: 0.00030717259117397553, accuracy: 0.7744004461795873\n",
      "Epoch 12/20, cost: 0.0007520366804180948, accuracy: 0.7707752370329057\n",
      "Epoch 13/20, cost: 0.00027833294360065394, accuracy: 0.7738427216954824\n",
      "Epoch 14/20, cost: 0.00033189301910434976, accuracy: 0.7738427216954824\n",
      "Epoch 15/20, cost: 0.0005146360319480642, accuracy: 0.7749581706636921\n",
      "Epoch 16/20, cost: 0.00020284362110164342, accuracy: 0.771611823759063\n",
      "Epoch 17/20, cost: 0.00016394774273348318, accuracy: 0.7757947573898494\n",
      "Epoch 18/20, cost: 0.0002572705761020615, accuracy: 0.7738427216954824\n",
      "Epoch 19/20, cost: 0.00021652888941751846, accuracy: 0.7741215839375348\n",
      "Epoch 20/20, cost: 0.00028501461910423396, accuracy: 0.7752370329057445\n",
      "Accuracy: 0.7752370329057445, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=16, learning_rate=0.01\n",
      "Epoch 1/20, cost: 0.03485954187870118, accuracy: 0.7032905744562187\n",
      "Epoch 2/20, cost: 0.002315958240361693, accuracy: 0.7738427216954824\n",
      "Epoch 3/20, cost: 0.000546860749475105, accuracy: 0.7752370329057445\n",
      "Epoch 4/20, cost: 0.0004583410222989397, accuracy: 0.77356385945343\n",
      "Epoch 5/20, cost: 0.0002208620633425319, accuracy: 0.7744004461795873\n",
      "Epoch 6/20, cost: 6.422222472586174e-05, accuracy: 0.7763524818739542\n",
      "Epoch 7/20, cost: 0.00031441801385224434, accuracy: 0.7766313441160066\n",
      "Epoch 8/20, cost: 2.5448521199995707e-05, accuracy: 0.7785833798103736\n",
      "Epoch 9/20, cost: 0.000516155101548277, accuracy: 0.7816508644729504\n",
      "Epoch 10/20, cost: 0.00029292663435657486, accuracy: 0.783324037925265\n",
      "Epoch 11/20, cost: 0.0009886689115885387, accuracy: 0.7847183491355271\n",
      "Epoch 12/20, cost: 0.00011504838667110746, accuracy: 0.7841606246514222\n",
      "Epoch 13/20, cost: 7.887276244849997e-05, accuracy: 0.7847183491355271\n",
      "Epoch 14/20, cost: 2.5415319781370386e-05, accuracy: 0.7844394868934746\n",
      "Epoch 15/20, cost: 3.860648009777058e-05, accuracy: 0.7844394868934746\n",
      "Epoch 16/20, cost: 0.000128802951110553, accuracy: 0.7849972113775795\n",
      "Epoch 17/20, cost: 1.677297156933716e-05, accuracy: 0.7858337981037368\n",
      "Epoch 18/20, cost: 0.0001375517327999218, accuracy: 0.7855549358616843\n",
      "Epoch 19/20, cost: 6.517816590019158e-05, accuracy: 0.7855549358616843\n",
      "Epoch 20/20, cost: 6.087671227064939e-05, accuracy: 0.7852760736196319\n",
      "Accuracy: 0.7852760736196319, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=32, learning_rate=0.001\n",
      "Epoch 1/20, cost: 0.1598331486362123, accuracy: 0.7211377579475738\n",
      "Epoch 2/20, cost: 0.06724896747198701, accuracy: 0.7420524261015059\n",
      "Epoch 3/20, cost: 0.03734067008877722, accuracy: 0.7437255995538204\n",
      "Epoch 4/20, cost: 0.037986240555980225, accuracy: 0.7431678750697156\n",
      "Epoch 5/20, cost: 0.01231646959649608, accuracy: 0.739542665923034\n",
      "Epoch 6/20, cost: 0.011860057267066949, accuracy: 0.741494701617401\n",
      "Epoch 7/20, cost: 0.008232846119697206, accuracy: 0.7403792526491912\n",
      "Epoch 8/20, cost: 0.004420882863589439, accuracy: 0.7417735638594535\n",
      "Epoch 9/20, cost: 0.005251148372930112, accuracy: 0.7426101505856108\n",
      "Epoch 10/20, cost: 0.007069033775502886, accuracy: 0.7448410485220301\n",
      "Epoch 11/20, cost: 0.007286212628780588, accuracy: 0.7440044617958729\n",
      "Epoch 12/20, cost: 0.005819643427450499, accuracy: 0.7462353597322923\n",
      "Epoch 13/20, cost: 0.0030089386279590594, accuracy: 0.7426101505856108\n",
      "Epoch 14/20, cost: 0.0032845978835376564, accuracy: 0.7445621862799777\n",
      "Epoch 15/20, cost: 0.0031927558814719456, accuracy: 0.7442833240379253\n",
      "Epoch 16/20, cost: 0.003378942632475613, accuracy: 0.7437255995538204\n",
      "Epoch 17/20, cost: 0.0032975134330128905, accuracy: 0.7445621862799777\n",
      "Epoch 18/20, cost: 0.002530161432519135, accuracy: 0.7456776352481874\n",
      "Epoch 19/20, cost: 0.0024985736269453615, accuracy: 0.7462353597322923\n",
      "Epoch 20/20, cost: 0.002361066251182619, accuracy: 0.7456776352481874\n",
      "Accuracy: 0.7456776352481874, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=32, learning_rate=0.002\n",
      "Epoch 1/20, cost: 0.06415292140080368, accuracy: 0.7367540435025097\n",
      "Epoch 2/20, cost: 0.026392329916879897, accuracy: 0.7431678750697156\n",
      "Epoch 3/20, cost: 0.021188325022979192, accuracy: 0.7431678750697156\n",
      "Epoch 4/20, cost: 0.0068282438412003285, accuracy: 0.7467930842163971\n",
      "Epoch 5/20, cost: 0.00418979452017922, accuracy: 0.745398773006135\n",
      "Epoch 6/20, cost: 0.005742545098774163, accuracy: 0.7529280535415505\n",
      "Epoch 7/20, cost: 0.00334943644051512, accuracy: 0.7481873954266592\n",
      "Epoch 8/20, cost: 0.002628913271283037, accuracy: 0.7459564974902398\n",
      "Epoch 9/20, cost: 0.004077837880571139, accuracy: 0.7467930842163971\n",
      "Epoch 10/20, cost: 0.0012885357013000833, accuracy: 0.7476296709425544\n",
      "Epoch 11/20, cost: 0.002953450557389991, accuracy: 0.7487451199107641\n",
      "Epoch 12/20, cost: 0.001736534762160762, accuracy: 0.7495817066369214\n",
      "Epoch 13/20, cost: 0.0024710187639727693, accuracy: 0.7498605688789738\n",
      "Epoch 14/20, cost: 0.0019382837372657145, accuracy: 0.7481873954266592\n",
      "Epoch 15/20, cost: 0.0019489140905516037, accuracy: 0.7476296709425544\n",
      "Epoch 16/20, cost: 0.002055143502876216, accuracy: 0.7487451199107641\n",
      "Epoch 17/20, cost: 0.0008468199114359782, accuracy: 0.7490239821528165\n",
      "Epoch 18/20, cost: 0.0008390829963524274, accuracy: 0.7481873954266592\n",
      "Epoch 19/20, cost: 0.0015808951547204104, accuracy: 0.7487451199107641\n",
      "Epoch 20/20, cost: 0.0010668886771950405, accuracy: 0.7476296709425544\n",
      "Accuracy: 0.7476296709425544, Best Accuracy: 0.7875069715560513\n",
      "Training with params:nodes=64, epochs=20, mb_size=32, learning_rate=0.005\n",
      "Epoch 1/20, cost: 0.01274451423953371, accuracy: 0.752649191299498\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T04:00:08.549614Z",
     "start_time": "2025-01-24T04:00:08.513467Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Best Accuracy: {best_accuracy} with parameters: {best_params}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8006134969325154 with parameters: (64, 5, 64, 0.005)\n"
     ]
    }
   ],
   "execution_count": 116
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
